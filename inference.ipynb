{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b68b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loadlibs import *\n",
    "import functions\n",
    "import modules\n",
    "# from configs import OUTPUT, CFG, TOOLS, DIRECTORY, INFERENCE_MODELS\n",
    "CFG = {\n",
    "    # train setting\n",
    "    'EPOCHS':20,\n",
    "    'WARM_UP_EPOCHS':6,\n",
    "    'BATCH_SIZE': 128,\n",
    "    'VISIBLE_TQDM' : True,\n",
    "    'PARALLEL' : False,\n",
    "    'MIXED_PRECISION' : True, \n",
    "    'SEED': None,\n",
    "    'LEARNING_RATE':0.003,\n",
    "    'CONTINUE' : False,\n",
    "    'CONTINUE2' : False,\n",
    "    \n",
    "    # augmentation\n",
    "    'CUTMIX' : True, \n",
    "    'ONES' : False,\n",
    "    'ROTATION': False,\n",
    "    'TRANSLATION': False, \n",
    "    'NUM_AUGS_TYPE': 0, \n",
    "    'NUM_AUGS' : 2,\n",
    "    \n",
    "    # image\n",
    "    'IMG_HEIGHT_SIZE':64,\n",
    "    'IMG_WIDTH_SIZE':192,\n",
    "    'GRAY_SCALE': True,\n",
    "    'INPUT_CHANNEL': 1,\n",
    "\n",
    "    # data loading \n",
    "    'NUM_WORKERS':2,\n",
    "    'TEST_SIZE':0.2,\n",
    "    \n",
    "    # model\n",
    "    'NUM_FIDUCIAL': 20,\n",
    "    \n",
    "        # cnn\n",
    "    'PRETRAINED' : True,\n",
    "    'CNN_TYPE': None, \n",
    "    'CNN_OUTPUT': None,            \n",
    "\n",
    "        # rnn (transformer)\n",
    "    # 'SEQ_HIDDEN_SIZE': 768,\n",
    "    'SEQ_HIDDEN_SIZE': 1024,\n",
    "    'SEQ_TYPE' : None,\n",
    "    'SEQ_ACTIVATION' : torch.nn.GELU(approximate='tanh'),\n",
    "    'SEQ_NUM_LAYERS': 2,\n",
    "    'SEQ_BIDIRECTIONAL': True,\n",
    "    'NUM_HEADS': 4,\n",
    "        \n",
    "            # rnn -> conformer encoder\n",
    "\n",
    "        # pred    \n",
    "    'NUM_CLASS': 2350,\n",
    "\n",
    "    # etc\n",
    "    'DROPOUT' : 0.2,\n",
    "    'DROPPATH' : 0.2,\n",
    "    'DROPBLOCK' : 0.2, \n",
    "    'DEVICE' :  'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'NUM_DEVICE' : None,\n",
    "}\n",
    "\n",
    "DIRECTORY = {\n",
    "    'TRAIN_DIR' : \"/home/gyuseonglee/workspace/2301_OCR/data/train.csv\",\n",
    "    'TEST_DIR'  : \"/home/gyuseonglee/workspace/2301_OCR/data/test.csv\",\n",
    "    'SUBMIT_DIR' : \"/home/gyuseonglee/workspace/2301_OCR/data/sample_submission.csv\",\n",
    "    \n",
    "    'TRAIN_IMAGE_DIR' : \"/home/gyuseonglee/workspace/2301_OCR/data/train\",\n",
    "    'TEST_IMAGE_DIR'  : \"/home/gyuseonglee/workspace/2301_OCR/data/test\",\n",
    "    \n",
    "    'CUTMIX' : \"/home/gyuseonglee/workspace/2301_OCR/data/cutmix.csv\",\n",
    "    'ONES' : \"/home/gyuseonglee/workspace/2301_OCR/data/ones.csv\",\n",
    "    'TWOS' : \"/home/gyuseonglee/workspace/2301_OCR/data/twos.csv\",\n",
    "    'THREES' : \"/home/gyuseonglee/workspace/2301_OCR/data/threes.csv\",\n",
    "    \n",
    "}\n",
    "\n",
    "train, valid, test, submit = functions.prepare_data(CFG, DIRECTORY)\n",
    "idx2char, char2idx = functions.prepare_vocab(train)\n",
    "_, _, test_loader = functions.prepare_loader(train, valid, test, CFG)\n",
    "today = datetime.datetime.strftime(datetime.datetime.today(), '%y%m%d')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b627f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(models, test_loader, idx2char, configs):\n",
    "    global cur_probs, probs, yhat\n",
    "    print(f\"-- number of models : {len(models)}\")\n",
    "    def decode_predictions(text_batch_logits):\n",
    "        text_batch_tokens = F.softmax(text_batch_logits, 2).argmax(2) # [T, batch_size]\n",
    "        text_batch_tokens = text_batch_tokens.numpy().T # [batch_size, T]\n",
    "        text_batch_tokens_new = []\n",
    "        for text_tokens in text_batch_tokens:\n",
    "            text = [idx2char[idx] for idx in text_tokens]\n",
    "            text = \"\".join(text)\n",
    "            text_batch_tokens_new.append(text)\n",
    "        return text_batch_tokens_new\n",
    "    \n",
    "    probs = []\n",
    "    for idx in range(len(models)):\n",
    "        model = torch.load(models[idx], map_location=configs['DEVICE']).module\n",
    "        model = model.to(configs['DEVICE'])\n",
    "        if configs['PARALLEL'] == True:\n",
    "            model = torch.nn.parallel.DataParallel(model)\n",
    "        model.eval()\n",
    "        cur_probs = []\n",
    "        probs_sum = torch.zeros(12, 74121, 2350)\n",
    "        with torch.no_grad():\n",
    "            if configs['VISIBLE_TQDM']:\n",
    "                test_iterator = tq(test_loader)\n",
    "            else:\n",
    "                test_iterator = test_loader\n",
    "            \n",
    "            for batch in test_iterator:\n",
    "                batch = batch.to(configs['DEVICE'])        \n",
    "                yhat, _ = model(batch)\n",
    "                if configs['PARALLEL'] == True:\n",
    "                    yhat = yhat.permute(1,0,2)\n",
    "                yhat = yhat.cpu().detach()\n",
    "                cur_probs.append(yhat)\n",
    "        cur_probs = torch.vstack(cur_probs).permute(1,0,2)\n",
    "        probs_sum.add_(cur_probs)\n",
    "        del cur_probs\n",
    "    probs_sum/=len(models)    \n",
    "    \n",
    "    pred = decode_predictions(probs_sum.cpu()) \n",
    "       \n",
    "    return pred\n",
    "\n",
    "\n",
    "def inference_single(model, test_loader, idx2char, configs):\n",
    "    global preds, yhats, text_batch_pred, yhat\n",
    "    def decode_predictions(yhat):\n",
    "        text_batch_tokens = F.softmax(yhat, 2).argmax(2) # [T, batch_size]\n",
    "        # print(f\"test_batch_tokens.shape (should be [T, batch_size]) : {text_batch_tokens.shape}\")\n",
    "        text_batch_tokens = text_batch_tokens.numpy().T # [batch_size, T]\n",
    "        # print(f\"test_batch_tokens.shape (should be [batch_size, T]) : {text_batch_tokens.shape}\")\n",
    "        \n",
    "        text_batch_tokens_new = []\n",
    "        for text_tokens in text_batch_tokens:\n",
    "            text = [idx2char[idx] for idx in text_tokens]\n",
    "            text = \"\".join(text)\n",
    "            text_batch_tokens_new.append(text)\n",
    "        return text_batch_tokens_new\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    yhats = []\n",
    "    with torch.no_grad():\n",
    "        test_iterator = tq(test_loader) if configs['VISIBLE_TQDM'] else test_loader\n",
    "        \n",
    "        for image_batch in test_iterator:\n",
    "            image_batch = image_batch.to(configs['DEVICE'])\n",
    "            yhat, _ = model(image_batch)\n",
    "            if configs['PARALLEL'] == True:\n",
    "                yhat = yhat.permute(1,0,2)\n",
    "            yhat = yhat.cpu()\n",
    "            text_batch_pred = decode_predictions(yhat)\n",
    "            \n",
    "#             preds.extend(text_batch_pred)\n",
    "            yhats.append(yhat)\n",
    "\n",
    "    return preds, yhats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1a3fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_prediction(word):\n",
    "    def remove_duplicates(text):\n",
    "        if len(text) > 1:\n",
    "            letters = [text[0]] + [letter for idx, letter in enumerate(text[1:], start=1) if text[idx] != text[idx-1]]\n",
    "        elif len(text) == 1:\n",
    "            letters = [text[0]]\n",
    "        else:\n",
    "            return \"\"\n",
    "        return \"\".join(letters)\n",
    "        \n",
    "    parts = word.split(\"-\")\n",
    "    parts = [remove_duplicates(part) for part in parts]\n",
    "    corrected_word = \"\".join(parts)\n",
    "    return corrected_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "622e49bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFER_MODELS = [\n",
    "    \"/home/gyuseonglee/workspace/2301_OCR/Aug-RegNet-TransformerDecoder_con20_42/model.pt\",\n",
    "    \"/home/gyuseonglee/workspace/2301_OCR/Aug-RegNet-TransformerDecoder_con20_1203/model.pt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f06fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of models : 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501fc69257fc41c09b23b4ba481d9b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5752d54bfe7e402fb6c1f570f2f3824d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = inference(INFER_MODELS, test_loader, idx2char, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5bfb707",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['label'] = pred\n",
    "submit['label'] = submit['label'].apply(correct_prediction)\n",
    "submit.to_csv(f'voting_submission_{today}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b90b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77f294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d8f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_model = torch.load(INFER_MODELS[0], map_location='cpu').module\n",
    "cur_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yhats[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = yhats[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08166245",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae572047",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d207840",
   "metadata": {},
   "outputs": [],
   "source": [
    "vstacked = torch.vstack(out)\n",
    "vstacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1df861",
   "metadata": {},
   "outputs": [],
   "source": [
    "vstacked.permute(1,0,2).shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
